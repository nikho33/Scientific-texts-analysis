@article{Allahyari2017,
abstract = {The amount of text that is generated every day is increasing dramatically. This tremendous volume of mostly unstructured text cannot be simply processed and perceived by computers. Therefore, efficient and effective techniques and algorithms are required to discover useful patterns. Text mining is the task of extracting meaningful information from text, which has gained significant attentions in recent years. In this paper, we describe several of the most fundamental text mining tasks and techniques including text pre-processing, classification and clustering. Additionally, we briefly explain text mining in biomedical and health care domains.},
archivePrefix = {arXiv},
arxivId = {1707.02919},
author = {Allahyari, Mehdi and Pouriyeh, Seyedamin and Assefi, Mehdi and Safaei, Saied and Trippe, Elizabeth D. and Gutierrez, Juan B. and Kochut, Krys},
eprint = {1707.02919},
file = {:C$\backslash$:/Users/nicol/Documents/Python scripts/Scientific-texts-analysis/biblio/2017{\_}A Brief Survey of Text Mining Classification, Clustering and Extraction Techniques{\_}Allahyari.pdf:pdf},
keywords = {classification,clustering,information extraction,information retrieval,text mining},
title = {{A Brief Survey of Text Mining: Classification, Clustering and Extraction Techniques}},
url = {http://arxiv.org/abs/1707.02919},
year = {2017}
}
@unpublished{Busemann1998,
author = {Busemann, Stephan},
file = {:C$\backslash$:/Users/nicol/Documents/Python scripts/Scientific-texts-analysis/biblio/1998{\_}Automated Text Summarization{\_}Busemann.pdf:pdf},
title = {{Automated Text Summarization}},
year = {1998}
}
@misc{Chang2015,
abstract = {A contextual analysis engine systematically extracts, ana lyzes and organizes digital content stored in an electronic file Such as a webpage. Content can be extracted using a text extraction module which is capable of separating the content which is to be analyzed from less meaningful content Such as format specifications and programming Scripts. The resulting unstructured corpus of plain text can then be passed to a text analytics module capable of generating a structured catego rization of topics included within the content. This structured categorization can be organized based on a content topic ontology which may have been previously defined or which may be developed in real-time. The systems disclosed herein optionally include an input/output interface capable of man aging workflows of the text extraction module and the text analytics module, administering a cache of previously gener ated results, and interfacing with otherapplications that lever age the disclosed contextual analysis services.},
author = {Chang, Walter and Chen, Chris and Sadler, Shone and Jared, David},
file = {:C$\backslash$:/Users/nicol/Documents/Python scripts/Scientific-texts-analysis/biblio/US20150106157A1{\_}Text Extraction Module for Contextual Analysis Engine.pdf:pdf},
title = {{Text extraction module for contextual analysis engine}},
year = {2015}
}
@article{Hashimi2015,
abstract = {Text mining techniques include categorization of text, summarization, topic detection, concept extraction, search and retrieval, document clustering, etc. Each of these techniques can be used in finding some non-trivial information from a collection of documents. Text mining can also be employed to detect a document's main topic/theme which is useful in creating taxonomy from the document collection. Areas of applications for text mining include publishing, media, telecommunications, marketing, research, healthcare, medicine, etc. Text mining has also been applied on many applications on the World Wide Web for developing recommendation systems. We propose here a set of criteria to evaluate the effectiveness of text mining techniques in an attempt to facilitate the selection of appropriate technique.},
author = {Hashimi, Hussein and Hafez, Alaaeldin and Mathkour, Hassan},
doi = {10.1016/j.chb.2014.10.062},
file = {:C$\backslash$:/Users/nicol/Documents/Python scripts/Scientific-texts-analysis/biblio/2015{\_}Selection criteria for text mining approaches{\_}Hashimi.pdf:pdf},
issn = {07475632},
journal = {Computers in Human Behavior},
keywords = {Classification,Clustering,Selection criteria,Text mining approaches},
pages = {729--733},
publisher = {Elsevier Ltd},
title = {{Selection criteria for text mining approaches}},
url = {http://dx.doi.org/10.1016/j.chb.2014.10.062},
volume = {51},
year = {2015}
}
@article{Nasukawa2009,
abstract = {As the use of IT systems expands, growing amounts of textual data are being generated, stored, and searched. This trend is widely believed to be causing information overload. Although the increase of accessible data is intended to increase our knowledge and yield insights for better actions, the data glut is making it hard to find meaning. Natural Language Processing (NLP) is a key technology to exploit text data, so applications for NLP are increasing rapidly. Such applications often exploit text mining, but they involve a broad range of NLP technologies as the applications develop. This new trend is generating new demands for NLP that require more research.},
author = {Nasukawa, Tetsuya and Nagano, Tohru},
doi = {10.1109/SNLP.2009.5340951},
file = {:C$\backslash$:/Users/nicol/Documents/Python scripts/Scientific-texts-analysis/biblio/2001{\_}Text analysis and knowledge mining system{\_}Nasukawa.pdf:pdf},
isbn = {9781424441389},
journal = {2009 8th International Symposium on Natural Language Processing, SNLP '09},
number = {4},
pages = {1--2},
title = {{Text analysis and knowledge mining}},
volume = {40},
year = {2009}
}
@article{Tshitoyan2019,
abstract = {The overwhelming majority of scientific knowledge is published as text, which is difficult to analyse by either traditional statistical analysis or modern machine learning methods. By contrast, the main source of machine-interpretable data for the materials research community has come from structured property databases1,2, which encompass only a small fraction of the knowledge present in the research literature. Beyond property values, publications contain valuable knowledge regarding the connections and relationships between data items as interpreted by the authors. To improve the identification and use of this knowledge, several studies have focused on the retrieval of information from scientific literature using supervised natural language processing3–10, which requires large hand-labelled datasets for training. Here we show that materials science knowledge present in the published literature can be efficiently encoded as information-dense word embeddings11–13 (vector representations of words) without human labelling or supervision. Without any explicit insertion of chemical knowledge, these embeddings capture complex materials science concepts such as the underlying structure of the periodic table and structure–property relationships in materials. Furthermore, we demonstrate that an unsupervised method can recommend materials for functional applications several years before their discovery. This suggests that latent knowledge regarding future discoveries is to a large extent embedded in past publications. Our findings highlight the possibility of extracting knowledge and relationships from the massive body of scientific literature in a collective manner, and point towards a generalized approach to the mining of scientific literature.},
author = {Tshitoyan, Vahe and Dagdelen, John and Weston, Leigh and Dunn, Alexander and Rong, Ziqin and Kononova, Olga and Persson, Kristin A. and Ceder, Gerbrand and Jain, Anubhav},
doi = {10.1038/s41586-019-1335-8},
file = {:C$\backslash$:/Users/nicol/Documents/Python scripts/Scientific-texts-analysis/biblio/2019{\_}Unsupervised word embeddings capture latent knowledge from materials science literature{\_}Tshitoyan.pdf:pdf},
issn = {14764687},
journal = {Nature},
number = {7763},
pages = {95--98},
publisher = {Springer US},
title = {{Unsupervised word embeddings capture latent knowledge from materials science literature}},
url = {http://dx.doi.org/10.1038/s41586-019-1335-8},
volume = {571},
year = {2019}
}
@article{Wang2018,
abstract = {Automobile insurance fraud represents a pivotal percentage of property insurance companies' costs and affects the companies' pricing strategies and social economic benefits in the long term. Automobile insurance fraud detection has become critically important for reducing the costs of insurance companies. Previous studies on automobile insurance fraud detection examined various numeric factors, such as the time of the claim and the brand of the insured car. However, the textual information in the claims has rarely been studied to analyze insurance fraud. This paper proposes a novel deep learning model for automobile insurance fraud detection that uses Latent Dirichlet Allocation (LDA)-based text analytics. In our proposed method, LDA is first used to extract the text features hiding in the text descriptions of the accidents appearing in the claims, and deep neural networks then are trained on the data, which include the text features and traditional numeric features for detecting fraudulent claims. Based on the real-world insurance fraud dataset, our experimental results reveal that the proposed text analytics-based framework outperforms a traditional one. Furthermore, the experimental results show that the deep neural networks outperform widely used machine learning models, such as random forests and support vector machine. Therefore, our proposed framework that combines deep neural networks and LDA is a suitable potential tool for automobile insurance fraud detection.},
author = {Wang, Yibo and Xu, Wei},
doi = {10.1016/j.dss.2017.11.001},
file = {:C$\backslash$:/Users/nicol/Documents/Python scripts/Scientific-texts-analysis/biblio/2018{\_}Leveraging deep learning with LDA-based text analytics to detect automobile insurance fraud{\_}Wang.pdf:pdf},
issn = {01679236},
journal = {Decision Support Systems},
keywords = {Deep learning,Fraud detection,Insurance fraud,Text analytics,Topic modeling},
pages = {87--95},
publisher = {Elsevier B.V},
title = {{Leveraging deep learning with LDA-based text analytics to detect automobile insurance fraud}},
url = {http://dx.doi.org/10.1016/j.dss.2017.11.001},
volume = {105},
year = {2018}
}
